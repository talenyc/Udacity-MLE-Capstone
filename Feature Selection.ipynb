{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('output/database.sqlite')\n",
    "data = pd.read_sql(\"SELECT *  \\\n",
    "FROM Scorecard \\\n",
    "WHERE 1 = 1 \\\n",
    "AND md_earn_wne_p6 != 'PrivacySuppressed' AND md_earn_wne_p6 IS NOT NULL \\\n",
    "\", con)\n",
    "#Year = 2011\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_target = ['md_earn_wne_p6']\n",
    "\n",
    "cols_school = ['PREDDEG', 'HIGHDEG', 'CONTROL', 'NUMBRANCH', 'AVGFACSAL']\n",
    "#                'PCIP01', 'PCIP03', 'PCIP04', 'PCIP05', 'PCIP09', 'PCIP10',\n",
    "#                'PCIP11', 'PCIP12', 'PCIP13', 'PCIP14', 'PCIP15', 'PCIP16',\n",
    "#                'PCIP19', 'PCIP22', 'PCIP23', 'PCIP24', 'PCIP25', 'PCIP26',\n",
    "#                'PCIP27', 'PCIP29', 'PCIP30', 'PCIP31', 'PCIP38', 'PCIP39',\n",
    "#                'PCIP40', 'PCIP41', 'PCIP42', 'PCIP43', 'PCIP44', 'PCIP45',\n",
    "#                'PCIP46', 'PCIP47', 'PCIP48', 'PCIP49', 'PCIP50', 'PCIP51',\n",
    "#                'PCIP52', 'PCIP54']\n",
    "\n",
    "# cols_admissions = ['ADM_RATE', 'SATVR25', 'SATVR75', 'SATMT25', 'SATMT75', 'SAT_AVG']\n",
    "cols_admissions = ['ADM_RATE', 'SAT_AVG']\n",
    "\n",
    "\n",
    "cols_costs = ['TUITFTE']\n",
    "\n",
    "cols_studentbody = ['UGDS', 'UGDS_NRA', 'PPTUG_EF', 'UG25abv',\n",
    "                    'PAR_ED_PCT_1STGEN', 'DEP_INC_AVG', 'IND_INC_AVG',\n",
    "                    'COMP_ORIG_YR2_RT', 'WDRAW_ORIG_YR2_RT', 'ENRL_ORIG_YR2_RT',\n",
    "                    'COMP_ORIG_YR4_RT', 'WDRAW_ORIG_YR4_RT', 'ENRL_ORIG_YR4_RT',\n",
    "                    'OVERALL_YR2_N', 'OVERALL_YR3_N', 'OVERALL_YR4_N',\n",
    "                    'OVERALL_YR6_N', 'OVERALL_YR8_N', 'count_nwne_p6']\n",
    "\n",
    "cols_financialaid = ['DEBT_MDN', 'GRAD_DEBT_MDN', 'WDRAW_DEBT_MDN']\n",
    "\n",
    "cols_other = []\n",
    "#['type']\n",
    "\n",
    "\n",
    "    \n",
    "#data_reduced = data[cols_target+cols_school+cols_admissions+cols_costs+\\\n",
    "#                    cols_studentbody+cols_financialaid+cols_other]\n",
    "\n",
    "data_reduced = data[data.describe().columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_reduced[(data_reduced.CONTROL=='Private for-profit') ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explore response variable for lineriatry\n",
    "plt.figure()\n",
    "#sns.distplot(data_reduced[cols_target])\n",
    "sns.distplot(data_reduced[data.CONTROL=='Public'][cols_target], label ='Public')\n",
    "sns.distplot(data_reduced[(data.CONTROL=='Private nonprofit')][cols_target], label='Private nonprofit')\n",
    "sns.distplot(data_reduced[(data.CONTROL=='Private for-profit')][cols_target] , label= 'Private for-profit')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"CONTROL\", y=\"md_earn_wne_p6\", data=data,\n",
    "            order=np.sort(data.CONTROL.unique()), color='White',\n",
    "            fliersize=0, width=0.25)\n",
    "sns.stripplot(x=\"CONTROL\", y=\"md_earn_wne_p6\", data=data,\n",
    "              order=np.sort(data.CONTROL.unique()),\n",
    "              alpha=0.25, size=5,\n",
    "              color='#348ABD', edgecolor='#348ABD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1 PCA\n",
    "#Scale the features and center \n",
    "from sklearn import preprocessing\n",
    "#X = data[cols_admissions+cols_costs+\\\n",
    "#                    cols_studentbody+cols_financialaid+cols_other]\n",
    "\n",
    "X = data[data.describe().columns]\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = data[cols_target].values\n",
    "\n",
    "print pd.DataFrame(X_scaled).shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination\n",
    "\n",
    "Recursive feature elimination is based on the idea to repeatedly construct a model (for example an SVM or a regression model) and choose either the best or worst performing feature (for example based on coefficients), setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. Features are then ranked according to when they were eliminated. As such, it is a greedy optimization for finding the best performing subset of features.\n",
    "\n",
    "The stability of RFE depends heavily on the type of model that is used for feature ranking at each iteration. Just as non-regularized regression can be unstable, so can RFE when utilizing it, while using ridge regression can provide more stable results.\n",
    "\n",
    "Sklearn provides RFE for recursive feature elimination and RFECV for finding the ranks together with optimal number of features via a cross validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/\n",
    "\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    " \n",
    "np.random.seed(0)\n",
    " \n",
    "\n",
    "X = X_scaled\n",
    " \n",
    " \n",
    "names = cols_admissions+cols_costs+\\\n",
    "                    cols_studentbody+cols_financialaid+cols_other\n",
    "\n",
    " \n",
    "ranks = {}\n",
    " \n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    " \n",
    "lr = LinearRegression(normalize=True)\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(X_scaled, y)\n",
    "ranks[\"Linear reg\"] = rank_to_dict(map(lambda x: round(x, 4), rfe.ranking_) , names)\n",
    "\n",
    "ridge = Ridge(alpha=0.1)\n",
    "rfe = RFE(ridge, n_features_to_select=1)\n",
    "rfe.fit(X_scaled,y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(map(lambda x: round(x, 4), rfe.ranking_) , names)\n",
    "\n",
    " \n",
    "\n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(X_scaled,y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    " \n",
    " \n",
    "\n",
    "#stop the search when 5 features are left (they will get equal scores)\n",
    "\n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe.fit(X_scaled,y)\n",
    "ranks[\"RFE\"] = rank_to_dict(map(float, rfe.ranking_), names, order=-1)\n",
    " \n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X_scaled, y)\n",
    "ranks[\"Stability\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_scaled,y)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    "\n",
    "f, pval  = f_regression(X_scaled, y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    "\n",
    "\n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "#for i in range(X.shape[1]):\n",
    "     #mine.compute_score(X[:,i], y)\n",
    "     #m = mine.mic()\n",
    "     #mic_scores.append(m)\n",
    " \n",
    "#ranks[\"MIC\"] = rank_to_dict(mic_scores, names) \n",
    " \n",
    " \n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    "\n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print \"\\t%s\" % \"\\t\".join(methods)\n",
    "for name in names:\n",
    "    print \"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods])))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To Evaluate variables I created a matrix of regressors and messured fature imortance.\n",
    "\n",
    "* Corr \n",
    "F-regression just computes the F statistic and pick the best features. F-regression does the following:\n",
    "- Start with a constant model, M0\n",
    "- Try all models M1 consisting of just one feature and pick the best according to the F statistic\n",
    "- Try all models M2 consisting of M1 plus one other feature and pick the best ...\n",
    "\n",
    "*  Recursive Feature Elimination (RFE) Recursive feature elimination is based on the idea to repeatedly construct a model (for example an SVM or a regression model) and choose either the best or worst performing feature (for example based on coefficients), setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. Features are then ranked according to when they were eliminated. As such, it is a greedy optimization for finding the best performing subset of features.\n",
    "\n",
    "Additionally I look at \n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Randomized Lasso \n",
    "- Random Forest \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of columns and its scores  I see some interesting obesvations:\n",
    "- Stability. Using Ridge regression for data interpretation due to its stability and the fact that useful features tend to have non-zero coefficients. \n",
    "\n",
    "Following features have low stability ( coefficients close to 0) and can be removed:\n",
    "* Percentage of undergraduates aged 25 and above\tUG25abv\n",
    "* Number of students in overall 3-year completion cohort\tOVERALL_YR3_N\n",
    "\n",
    "In previous tests I observed that Random Forests have the best predictive power messured by Median SQ Error MSE. \n",
    "Using Random Forest Feature Importances I can see tha following Features are most important:\n",
    "Average family income of dependent students in real 2014 dollars.\t DEP_INC_AVG <br>\n",
    "Percent who transferred to a 4-year institution and completed within 4 years\tCOMP_ORIG_YR4_RT <br>\n",
    "Average family income of independent students in real 2015 dollars.\tIND_INC_AVG <br>\n",
    "Average SAT equivalent score of students admitted\tSAT_AVG <br>\n",
    "Percent still enrolled at original institution within 2 years\tENRL_ORIG_YR2_RT <br>\n",
    "Enrollment of undergraduate certificate/degree-seeking students\tUGDS <br>\n",
    "Percent withdrawn from original institution within 2 years WDRAW_ORIG_YR2_RT <br>\n",
    "The median debt for students who have completed\tGRAD_DEBT_MDN <br>\n",
    "Percent completed within 2 years at original institution\tCOMP_ORIG_YR2_RT <br>\n",
    "Percentage first-generation students\t PAR_ED_PCT_1STGEN <br>\n",
    "Tuition revenue per full-time equivalent student\tTUITFTE <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
